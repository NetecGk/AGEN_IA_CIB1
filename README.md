<img src="images/neteclogo.png" alt="logo" width="300"/>

# IA Generativa en Ciberseguridad Avanzada

## Plataforma de laboratorios

Te damos la bienvenida a la **plataforma de laboratorios** del curso **IA Generativa en Ciberseguridad Avanzada**. Aqu√≠ podr√°s explorar diferentes tecnolog√≠as a trav√©s de pr√°cticas guiadas. ¬°Desarrolla tus habilidades y lleva tus conocimientos al siguiente nivel!

## Lista de laboratorios

Cada uno de estos laboratorios est√° dise√±ado para ofrecerte una experiencia pr√°ctica. Haz clic en los enlaces para comenzar.

### [Pr√°ctica 1. Crea agentes en el Copilot Studio de Teams](Cap√≠tulo1/Lab1-1.md) 
- **Descripci√≥n**: Identificar el uso de Copilot Studio, las limitantes  y las caracter√≠sticas de seguridad de los agentes cl√°sicos de Copilot Studio en Microsoft Teams.
- ‚è±Ô∏è **Duraci√≥n estimada**: 35 min.

### [Pr√°ctica 2. Nombre de la pr√°ctica](Cap√≠tulo1/Lab1-2.md)
  - **Descripci√≥n**: Crear y configurar un agente personalizado en Copilot Studio integrando datos empresariales desde SharePoint y ajustando sus respuestas mediante instrucciones espec√≠ficas. Configurar acciones automatizadas usando conectores, como el env√≠o de correos electr√≥nicos a trav√©s de Outlook, y establecer reglas para asegurar el flujo seguro de informaci√≥n.
- ‚è±Ô∏è **Duraci√≥n estimada**: 35 min.

### [Pr√°ctica 3. Desplegar MCP de referencia local, cargar dataset de ejemplo y ejecutar consultas seguras](Cap√≠tulo2/Lab2-1.md)
 - **Descripci√≥n**: Desplegar un servidor MCP de referencia local, integrando un modelo de lenguaje desde Azure AI Foundry y configurando el entorno de ejecuci√≥n en Ubuntu. Implementar pol√≠ticas de seguridad y autenticaci√≥n, incluyendo la generaci√≥n y uso de certificados digitales y una autoridad certificadora local. Ejecutar consultas seguras sobre el dataset cargado, utilizando Postman y verificando la comunicaci√≥n cifrada mediante mTLS y roles definidos.
- ‚è±Ô∏è**Duraci√≥n estimada**: 60 min.

### [Pr√°ctica 4. Desplegar un LLM Gateway local (proxy), a√±adir una regla simple de inspecci√≥n y probar rutas a provider mock](Cap√≠tulo3/Lab3-1.md) 
 - **Descripci√≥n**: Desplegar un LLM Gateway local que inspeccione prompts, enrute solicitudes a proveedores (Azure y mock) y exponga un endpoint de entrada. Configurar reglas de inspecci√≥n y ruteo (regex y palabras clave) para bloquear intentos de prompt injection y redirigir prompts seg√∫n condiciones definidas. Generar y revisar logs de eventos con request ID, simular su env√≠o a un SIEM y validar el comportamiento mediante peticiones curl/jq.
 - ‚è±Ô∏è **Duraci√≥n estimada**: 40 min.

### [Pr√°ctica 5. Crear workflow de caza de amenazas en n8n](Cap√≠tulo4/Lab4-1.md)
- **Descripci√≥n**: Configurar un flujo de caza de amenazas en n8n que incluya un Webhook de entrada, nodos HTTP Request, Set y Code para recopilar y enriquecer eventos desde el servidor Ubuntu. Normalizar y evaluar riesgos usando l√≥gica personalizada (nodo Code) y reglas condicionales (nodo IF) para asignar puntajes y clasificar niveles de riesgo. Orquestar acciones autom√°ticas y realizar pruebas: enviar bloqueos al servicio de mitigaci√≥n (/context/block), registrar eventos (/logs) y validar el flujo con Postman.
- ‚è±Ô∏è **Duraci√≥n estimada**: 60 min.

### [Pr√°ctica 6. Construir pipeline b√°sico de ingesti√≥n ‚Üí indexaci√≥n ‚Üí consulta RAG (usar datasets de prueba y validar sanitizaci√≥n)](Cap√≠tulo5/Lab5-1.md)
- **Descripci√≥n**: Construir un pipeline de ingesti√≥n, indexaci√≥n y consulta RAG usando Azure AI Foundry y Azure Cognitive Search; subir y vectorizar documentos, crear √≠ndices y desplegar modelos de embedding y generaci√≥n para consultas integradas; y validar la sanitizaci√≥n e integridad de datos mediante algoritmos hash y simular ataques para comprobar detecci√≥n y bloqueo.
- ‚è±Ô∏è**Duraci√≥n estimada**: 60 min.

### [Pr√°ctica 7. Simulaci√≥n de un prompt injection y aplicaci√≥n el playbook de respuesta](Cap√≠tulo6/Lab6-1.md) 
 - **Descripci√≥n**: Simular un ataque de prompt injection contra una aplicaci√≥n autenticada por Entra ID y observar su impacto en la interacci√≥n con el modelo; configurar filtros de contenido personalizados en Azure AI Foundry (content filters, blocklists y protecci√≥n PII) para bloquear y controlar prompts y respuestas; y validar el comportamiento de seguridad ejecutando la aplicaci√≥n, probando prompts maliciosos y leg√≠timos, y verificando el bloqueo y registro de eventos.
 - ‚è±Ô∏è **Duraci√≥n estimada**: 60 min.

### [Pr√°ctica 8. Evaluar el comportamiento de un modelo, uso de agentes, acciones y almacenamiento de registros de conversaci√≥n](Cap√≠tulo7/Lab7-1.md)
- **Descripci√≥n**: Evaluar el comportamiento de un modelo en Azure AI Foundry mediante pruebas manuales y m√©tricas de evaluaci√≥n, crear y configurar un agente contextualizado capaz de generar archivos con datos estructurados y ejecutar acciones mediante Code Interpreter, y revisar los registros de conversaci√≥n en Threads para asegurar la trazabilidad y validar que el agente haya actuado correctamente.
- ‚è±Ô∏è **Duraci√≥n estimada**: 60 min.

---

## üì¨ **Contacto y m√°s informaci√≥n**

Si tienes alguna pregunta o necesitas m√°s detalles, no dudes en [contactarnos](mailto:soporte@netec.com). Tambi√©n puedes encontrar m√°s recursos en nuestra [p√°gina](https://netec.com).

---

¬°Gracias por visitar nuestra plataforma! No olvides revisar todos los laboratorios y comenzar tu viaje de aprendizaje hoy mismo.
